{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GridWorld-Tabular-Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yogesh1q2w/PlanningGridWorld/blob/master/GridWorld_Tabular_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SamSQvCtVRAE",
        "colab_type": "code",
        "outputId": "fe512025-eb4c-4384-dcb0-d6f9e7d08cc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import tensorflow as tf\n",
        "from matplotlib import colors\n",
        "from collections import defaultdict\n",
        "import random"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH_sGmVrWffe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def printgrid(data):\n",
        "  # create discrete colormap\n",
        "  cmap = colors.ListedColormap(['red', 'blue','white','black'])\n",
        "  bounds = [0,1,2,3,4]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.imshow(data, cmap=cmap, norm=norm)\n",
        "\n",
        "  # draw gridlines\n",
        "  ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)\n",
        "  ax.set_xticks([])\n",
        "  ax.set_yticks([])\n",
        "  plt.show()\n",
        "\n",
        "def matfromfile(file):\n",
        "    with open(file,'r') as f:\n",
        "        s = []\n",
        "        t = []\n",
        "        r = f.read()\n",
        "        f.close()\n",
        "        l = 0\n",
        "        tt = 0\n",
        "        for j in r:\n",
        "            if(j == '\\n'):\n",
        "                s.append(t)\n",
        "                t = []\n",
        "                tt = 0\n",
        "                l += 1\n",
        "            else:\n",
        "                if j == '2':\n",
        "                    end = np.array([l,tt])\n",
        "                t.append(int(j))\n",
        "                tt += 1\n",
        "        s.append(t)\n",
        "        return np.array(s),end\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HkQv0KcXS5b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GridEnv:\n",
        "    def __init__(self,file, det=True):\n",
        "        self.gridfile = file\n",
        "        self.determ = det\n",
        "        self.grid, self.goal = matfromfile(self.gridfile) \n",
        "        self.nstates = np.size(self.grid)\n",
        "        self.nactions = 4\n",
        "        self.actions = ['l','r','u','d']\n",
        "        self.nrows = np.shape(self.grid)[0]\n",
        "        self.ncols = np.shape(self.grid)[1]\n",
        "        self.End = False\n",
        "        self.start = [np.random.randint(0,self.nrows),np.random.randint(0,self.ncols)]\n",
        "        while(self._gridval(self.start) == 0 or self._isEnd(self.start)):\n",
        "          self.start = [np.random.randint(0,self.nrows),np.random.randint(0,self.ncols)]\n",
        "        self.curr_state = self.start\n",
        "        \n",
        "    def _gridval(self,state):\n",
        "        return self.grid[state[0], state[1]]\n",
        "        \n",
        "    def _reward(self,state):\n",
        "        \n",
        "        if self.grid[state[0],state[1]] == 2:\n",
        "            return +5\n",
        "        elif self._gridval(state) == 0:   \n",
        "            return -2\n",
        "        else:\n",
        "            return -1\n",
        "        \n",
        "    def _isEnd(self,state):\n",
        "        if (self.grid[state[0], state[1]] == 2):\n",
        "          self.End = True\n",
        "        else:\n",
        "          self.End = False\n",
        "        return self.End\n",
        "        \n",
        "    def _nonDeterminsticTrans(self,action):\n",
        "        if action == 'u':\n",
        "            return np.random.choice(['u','l','r'], p = [0.8,0.1,0.1])\n",
        "        \n",
        "        if action == 'd':\n",
        "            return np.random.choice(['d','l','r'], p = [0.8,0.1,0.1])\n",
        "        \n",
        "        if action == 'l':\n",
        "            return np.random.choice(['l','u','d'], p = [0.8,0.1,0.1])\n",
        "        \n",
        "        if action == 'r':\n",
        "            return np.random.choice(['r','u','d'], p = [0.8,0.1,0.1])\n",
        "        \n",
        "    def sense(self,k):\n",
        "        s = self.curr_state\n",
        "        up = np.flip(self.grid[max(0,s[0]-k):s[0],s[1]])\n",
        "        down = self.grid[s[0]+1:min(self.nrows,s[0]+k+1),s[1]]\n",
        "        left = np.flip(self.grid[s[0],max(0,s[1]-k):s[1]])\n",
        "        right = self.grid[s[0],s[1]+1:min(self.ncols,s[1]+k+1)]\n",
        "        \n",
        "        if(np.size(up) > 0):\n",
        "            zr = np.where(up == 0)\n",
        "            if(np.size(zr) == 0):\n",
        "                filtup = up\n",
        "            else:\n",
        "                filtup = up[0:np.amin(zr)]\n",
        "        else:\n",
        "            filtup = np.array([])\n",
        "            \n",
        "        if(np.size(down) > 0):\n",
        "            zr = np.where(down == 0)\n",
        "            if(np.size(zr) == 0):\n",
        "                filtdown = down\n",
        "            else:\n",
        "                filtdown = down[0:np.amin(zr)]\n",
        "        else:\n",
        "            filtdown = np.array([])\n",
        "            \n",
        "        if(np.size(left) > 0):\n",
        "            zr = np.where(left == 0)\n",
        "            if(np.size(zr) == 0):\n",
        "                filtleft = left\n",
        "            else:\n",
        "                filtleft = left[0:np.amin(zr)]\n",
        "        else:\n",
        "            filtleft = np.array([])\n",
        "            \n",
        "        if(np.size(right) > 0):\n",
        "            zr = np.where(right == 0)\n",
        "            if(np.size(zr) == 0):\n",
        "                filtright = right\n",
        "            else:\n",
        "                filtright = right[0:np.amin(zr)]\n",
        "        else:\n",
        "            filtright = np.array([])\n",
        "            \n",
        "            \n",
        "        return np.array([filtup,filtdown,filtleft,filtright])\n",
        "        \n",
        "    def transition(self, action):\n",
        "        if self.determ:\n",
        "            if action == 'u':\n",
        "                nextState = self.curr_state + np.array([-1,0])\n",
        "            elif action == 'd':\n",
        "                nextState = self.curr_state + np.array([1,0])\n",
        "            elif action == 'l':\n",
        "                nextState = self.curr_state + np.array([0,-1])\n",
        "            elif action == 'r':\n",
        "                nextState = self.curr_state + np.array([0,1])\n",
        "                \n",
        "        else:\n",
        "            action = self._nonDeterminsticTrans(action)\n",
        "            self.determ = True\n",
        "            nextState,_,_ = self.transition(action)\n",
        "            self.determ = False\n",
        "            \n",
        "#         print(nextState)\n",
        "        if (nextState[0] >= 0) and (nextState[0] < self.nrows):\n",
        "            if (nextState[1] >= 0) and (nextState[1] < self.ncols):\n",
        "              if (self._gridval(nextState) != 0):\n",
        "                self.curr_state = nextState\n",
        "                return nextState,self._reward(nextState),self._isEnd(nextState)\n",
        "              else:\n",
        "                return self.curr_state,self._reward(nextState),self._isEnd(self.curr_state)\n",
        "        \n",
        "        return self.curr_state, self._reward(self.curr_state), self._isEnd(self.curr_state)\n",
        "             \n",
        "    def reset(self):\n",
        "        self.start = np.array([np.random.randint(0,self.nrows),np.random.randint(0,self.ncols)])\n",
        "        while(self._gridval(self.start) == 0 or self._isEnd(self.start)):\n",
        "          # print(self.start)\n",
        "          self.start = np.array([np.random.randint(0,self.nrows),np.random.randint(0,self.ncols)])\n",
        "        self.curr_state = self.start\n",
        "        self.End = False\n",
        "            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VSrPnbGUjZB",
        "colab_type": "code",
        "outputId": "c32fccb3-1f7f-4090-b159-f6602bad7213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "a = '(14,543)'\n",
        "a = a[1:-1]\n",
        "a.strip().split(',')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['14', '543']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iKIrrCGb6ou",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string(s):\n",
        "  return '(' + str(s[0]) + ',' + str(s[1]) + ')'\n",
        "\n",
        "def array(s):\n",
        "  s = s[1:-1]\n",
        "  l = s.strip().split(',')\n",
        "  return np.array([int(l[0]), int(l[1])])\n",
        "\n",
        "class SimpleAgent:\n",
        "    \n",
        "    def __init__(self, sense, goal):\n",
        "        self.senseCap = sense\n",
        "        self.actions = [0,1,2,3]\n",
        "        self.actd = {0:'u',1:'d',2:'l',3:'r'}\n",
        "        self.actrev = {'u':0,'d':1,'l':2,'r':3}\n",
        "        self.model = np.ones((nrow,ncol))*3\n",
        "        self.comps = DSU(nrow,ncol)\n",
        "        self.goal = goal\n",
        "        # print(goal)\n",
        "        self.model[goal[0],goal[1]] = 2\n",
        "        self.planbit = False                                                    #store if you are planning in current state\n",
        "        \n",
        "        self.lr = 0.2\n",
        "        self.epsilon = 0.1\n",
        "        self.gamma = 0.9\n",
        "        self.planeps = 0.9\n",
        "        self.Q_vals = defaultdict(lambda:[0.0,0.0,0.0,0.0])\n",
        "        self.with_bonus = False                                                 #change this parameter if(not) using bonuses--> Bonus = max(all_rewards_recieved until now)+2.0\n",
        "        self.inc_bonus = 2.0\n",
        "        self.pseudo_rwd = self.inc_bonus\n",
        "    \n",
        "    def learn(self, s, a, r, next_s):\n",
        "        a = self.actrev[a]\n",
        "        current_q = self.Q_vals[s][a]\n",
        "        if(self.comps.find(next_s) == self.comps.find(string(self.goal)) and self.planbit and self.with_bonus):\n",
        "          r = max(r + self.inc_bonus, self.pseudo_rwd)\n",
        "          self.planbit = False\n",
        "        new_q = r + self.gamma * max(self.Q_vals[next_s])\n",
        "        self.Q_vals[s][a] += self.lr * (new_q - current_q)\n",
        "\n",
        "    def explore(self,state,senseRes):\n",
        "      if np.random.rand() < self.epsilon:\n",
        "          safeExps = []\n",
        "          for i in range(0,4):\n",
        "            if len(senseRes[i] > 0):\n",
        "              safeExps.append(i)\n",
        "                  \n",
        "          action = np.random.choice(safeExps)\n",
        "          acList = [self.actd[action]]\n",
        "      else:\n",
        "          state_action = self.Q_vals[state]\n",
        "          action = self.arg_max(state_action)\n",
        "          acList = [self.actd[action]]\n",
        "      \n",
        "      return acList\n",
        "\n",
        "    def plan(self, state, senseRes):\n",
        "      strgoal = string(self.goal)\n",
        "      if self.comps.sameComp(state, strgoal):\n",
        "        acList = self.BFS(array(state),self.goal)\n",
        "      else:\n",
        "        acList = self.borderBFS(array(state))\n",
        "      \n",
        "      self.planbit = True\n",
        "      return acList\n",
        "\n",
        "    def pick_action(self, state, senseRes):\n",
        "      \n",
        "        if np.random.rand() < self.planeps and (not self.isBorder(array(state)) or self.comps.sameComp(state,string(self.goal))):\n",
        "          act1 = self.plan(state,senseRes)\n",
        "          return act1\n",
        "\n",
        "        else:\n",
        "          act1 = self.explore(state,senseRes)\n",
        "          return act1\n",
        "          \n",
        "\n",
        "    def BFS(self, source, goal):\n",
        "      q = []\n",
        "      q.append(source)\n",
        "      pred = {}\n",
        "      vis = defaultdict(lambda:0)\n",
        "      vis[string(source)] = 1\n",
        "      flagval = True\n",
        "      while (not len(q) == 0 and flagval):\n",
        "        u = q.pop(0)\n",
        "        for i in [[-1,0],[1,0],[0,-1],[0,1]]:\n",
        "          if not flagval:\n",
        "            break\n",
        "          coord = u+np.array(i)\n",
        "          if(coord[0] >= 0 and coord[0] < nrow and coord[1] >=0 and coord[1] < ncol):\n",
        "            if((self.model[coord[0],coord[1]] == 1 or self.model[coord[0],coord[1]] == 2)  and vis[string(coord)] == 0):\n",
        "              q.append(coord)\n",
        "              pred[string(coord)] = u\n",
        "              vis[string(coord)] = 1\n",
        "\n",
        "              if np.array_equal(coord,goal):\n",
        "                flagval = False\n",
        "                break\n",
        "      \n",
        "      acList = []\n",
        "      v = goal \n",
        "\n",
        "      actionmap = {'(1,0)':'d','(-1,0)':'u','(0,1)':'r','(0,-1)':'l'}\n",
        "\n",
        "      while(not np.array_equal(v,source)):\n",
        "        acList = [actionmap[string(v-pred[string(v)])]] + acList\n",
        "        v = pred[string(v)]\n",
        "\n",
        "      return acList\n",
        "      \n",
        "    def isBorder(self,state):\n",
        "      for i in [[-1,0],[1,0],[0,-1],[0,1]]:\n",
        "          coord = state+np.array(i)\n",
        "          if(coord[0] >= 0 and coord[0] < nrow and coord[1] >=0 and coord[1] < ncol):\n",
        "            if(self.model[coord[0],coord[1]] == 3):\n",
        "              return True\n",
        "      return False\n",
        "\n",
        "    def borderBFS(self, source):\n",
        "      border_states = []\n",
        "      q = []\n",
        "      q.append(source)\n",
        "      pred = {}\n",
        "      vis = defaultdict(lambda:0)\n",
        "      vis[string(source)] = 1\n",
        "      flagval = True\n",
        "      if(self.isBorder(source)):\n",
        "        border_states.append(source)\n",
        "      while (not len(q) == 0 and flagval):\n",
        "        u = q.pop(0)\n",
        "        for i in [[-1,0],[1,0],[0,-1],[0,1]]:\n",
        "          if not flagval:\n",
        "            break\n",
        "          coord = u+np.array(i)\n",
        "          if(coord[0] >= 0 and coord[0] < nrow and coord[1] >=0 and coord[1] < ncol):\n",
        "            if((self.model[coord[0],coord[1]] == 1 or self.model[coord[0],coord[1]] == 2) and vis[string(coord)] == 0):\n",
        "              q.append(coord)\n",
        "              if(self.isBorder(coord)):\n",
        "                border_states.append(coord)\n",
        "              pred[string(coord)] = u\n",
        "              vis[string(coord)] = 1\n",
        "\n",
        "              if np.array_equal(coord,self.goal):\n",
        "                flagval = False\n",
        "                break\n",
        "      \n",
        "      acList = []\n",
        "      # print(border_states)\n",
        "      v = border_states[np.random.randint(0,len(border_states))] \n",
        "\n",
        "      actionmap = {'(1,0)':'d','(-1,0)':'u','(0,1)':'r','(0,-1)':'l'}\n",
        "\n",
        "      while(not np.array_equal(v,source)):\n",
        "        acList = [actionmap[string(v-pred[string(v)])]] + acList\n",
        "        v = pred[string(v)]\n",
        "\n",
        "      return acList\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def arg_max(state_action):\n",
        "        '''\n",
        "            Select a random action from a list of actions with\n",
        "            equal Q values from a state\n",
        "        '''\n",
        "        max_index_list = []\n",
        "        max_value = state_action[0]\n",
        "        for index, value in enumerate(state_action):\n",
        "            if value > max_value:\n",
        "                max_index_list.clear()\n",
        "                max_value = value\n",
        "                max_index_list.append(index)\n",
        "            elif value == max_value:\n",
        "                max_index_list.append(index)\n",
        "        return random.choice(max_index_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3UeSUMQbtcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DSU:\n",
        "\n",
        "  def __init__(self, nrow, ncol):\n",
        "    self.parent = {}\n",
        "    self.rank = {}\n",
        "    for i in range(0,nrow):\n",
        "      for j in range(0,ncol):\n",
        "        self.parent[string([i,j])] = string([i,j])\n",
        "        self.rank[string([i,j])] = 0\n",
        "  \n",
        "  def find(self, elt):\n",
        "    if self.parent[elt] != elt:\n",
        "      self.parent[elt] = self.find(self.parent[elt])\n",
        "\n",
        "    return self.parent[elt]\n",
        "\n",
        "  def union(self,eltx, elty):\n",
        "    xroot = self.find(eltx)\n",
        "    yroot = self.find(elty)\n",
        "    \n",
        "    if (self.rank[xroot] < self.rank[yroot]):\n",
        "      self.parent[xroot] = yroot\n",
        "    elif (self.rank[xroot] > self.rank[yroot]):\n",
        "      self.parent[yroot] = xroot\n",
        "    else:\n",
        "      self.parent[yroot] = xroot\n",
        "      self.rank[xroot]+=1\n",
        "\n",
        "  def sameComp(self,x,y):\n",
        "    return self.find(x) == self.find(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltr3IbO-irp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nrow = 50\n",
        "ncol = 50\n",
        "env = GridEnv('50map.txt',1)\n",
        "agent = SimpleAgent(3,env.goal)\n",
        "n_epis = 10000\n",
        "max_len = 10000\n",
        "learn_steps = 5\n",
        "\n",
        "plot_rwds = []\n",
        "for episode in range(0,n_epis,learn_steps):\n",
        "\n",
        "  for step in range(0,learn_steps):\n",
        "    env.reset()\n",
        "    epi_len  = 0\n",
        "    while True:\n",
        "      state = env.curr_state\n",
        "      agent.model[state[0], state[1]] = 1\n",
        "      # print(episode,state)\n",
        "      sensorRes = env.sense(agent.senseCap)\n",
        "      for i,x in enumerate(sensorRes):\n",
        "        if i == 0:\n",
        "          agent.model[state[0]-x.shape[0]:state[0],state[1]] = np.flip(x)\n",
        "          for t in range(0,len(x)):\n",
        "            agent.comps.union(string(state),string([state[0]-t-1,state[1]]))\n",
        "          if(len(x) != agent.senseCap):\n",
        "            agent.model[state[0]-x.shape[0]-1,state[1]] = 0\n",
        "        elif i == 1:\n",
        "          agent.model[state[0]+1:state[0]+x.shape[0]+1,state[1]] = x\n",
        "          for t in range(0,len(x)):\n",
        "            agent.comps.union(string(state),string([state[0]+t+1,state[1]]))\n",
        "          if(len(x) != agent.senseCap):\n",
        "            agent.model[state[0]+x.shape[0]+1,state[1]] = 0\n",
        "        elif i == 2:\n",
        "          agent.model[state[0], state[1]-x.shape[0]:state[1]] = np.flip(x)\n",
        "          for t in range(0,len(x)):\n",
        "            agent.comps.union(string(state),string([state[0],state[1]-t-1]))\n",
        "          if(len(x) != agent.senseCap):\n",
        "            agent.model[state[0],state[1]-x.shape[0]-1] = 0\n",
        "        else:\n",
        "          agent.model[state[0], state[1]+1:state[1]+x.shape[0]+1] = x\n",
        "          for t in range(0,len(x)):\n",
        "            agent.comps.union(string(state),string([state[0],state[1]+t+1]))\n",
        "          if(len(x) != agent.senseCap):\n",
        "            if state[1]+x.shape[0]+1 < ncol:\n",
        "              agent.model[state[0],state[1]+x.shape[0]+1] = 0\n",
        "\n",
        "      action = agent.pick_action(string(state),sensorRes)\n",
        "      # print(action)\n",
        "\n",
        "      # done = False\n",
        "\n",
        "      for j in action:\n",
        "        next_state, rwd, done = env.transition(j)\n",
        "        agent.learn(string(state),j,rwd,string(next_state))\n",
        "\n",
        "        state = next_state\n",
        "        epi_len += 1\n",
        "          \n",
        "        if done or epi_len > max_len:\n",
        "          done = True\n",
        "          break\n",
        "      \n",
        "      # print('Step# ',step,'Epi_len=',epi_len)\n",
        "      agent.model[state[0],state[1]] = 2\n",
        "      printgrid(agent.model)\n",
        "      agent.model[state[0],state[1]] = 1\n",
        "\n",
        "      if done or epi_len > max_len:\n",
        "        break\n",
        "\n",
        "        \n",
        "\n",
        "  env.reset()\n",
        "  env.curr_state = env.start = np.array([48,1])\n",
        "  epi_len = 0\n",
        "  epi_rwd = 0\n",
        "  while True:\n",
        "    state = env.curr_state\n",
        "    # print(episode,state)\n",
        "    sensorRes = env.sense(agent.senseCap)\n",
        "    action = agent.pick_action(string(state),sensorRes)\n",
        "    done = False\n",
        "    for j in action:\n",
        "      next_state, rwd, done = env.transition(j)\n",
        "      epi_rwd += rwd\n",
        "\n",
        "      agent.learn(string(state),action,rwd,string(next_state))\n",
        "\n",
        "      state = next_state\n",
        "      epi_len += 1\n",
        "          \n",
        "      if done:\n",
        "          plot_rwds.append(epi_rwd)\n",
        "          break\n",
        "\n",
        "    if done:\n",
        "      break\n",
        "\n",
        "  # printgrid(agent.model)\n",
        "\n",
        "  print('Episode# ', episode, ' , Episode stats: ', epi_rwd, '/' , epi_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFQvKGumkXox",
        "colab_type": "code",
        "outputId": "1eb3bd65-b609-45be-8d42-e50b5f6e64e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "agent.borderBFS(np.array([12,37]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['u', 'u', 'u', 'u', 'u', 'u', 'r', 'r', 'r', 'r', 'u', 'u']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLpj1xqRooyo",
        "colab_type": "code",
        "outputId": "113ed4b1-bb11-4eef-8c7f-8dbd65322bc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "agent.curr_state = np.array([1,47])\n",
        "env.sense(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array([], dtype=int64), array([1, 1, 1]), array([1, 1, 1]),\n",
              "       array([1, 1, 2])], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wNbLC6Y4UGSP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "printgrid(env.grid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUOsY-0kKNyK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "v = [np.array([1]), np.array([2])]\n",
        "v[np.random.randint(0,len(v))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnlwoFrMjBSc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def proc(rews,k = 5):\n",
        "    prews = []\n",
        "    for i in range(0,len(rews),k):\n",
        "        prews.append(sum(rews[i:i+k])/k)\n",
        "    return prews"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CTAGIFl6CiT",
        "colab_type": "code",
        "outputId": "2ed7240b-8ed5-44ed-e19b-fb135b730650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpODMbCE5vrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('/content/drive/My Drive/Planning Project/plots/GridWorld-Deterministic-Model_50map.npy',plot_rwds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbR5FPJRwJOT",
        "colab_type": "code",
        "outputId": "1e63e821-5da8-4980-fb0a-a1a455e94b9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "rs = proc(plot_rwds,1)\n",
        "plt.plot(rs,'r-')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Average Reward')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c94e1fd4ec06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_rwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Average Reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'proc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyJn_-Z8n5_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "env.curr_state = np.array([1,1])\n",
        "env.sense(3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BYHJAfTe7Bx",
        "colab_type": "code",
        "outputId": "b0ff5457-8e67-4c96-e5c2-a6886971a5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "plot_rwds = np.load('/content/drive/My Drive/Planning Project/plots/GridWorld-Deterministic-Model_50map.npy')\n",
        "len(d)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    }
  ]
}